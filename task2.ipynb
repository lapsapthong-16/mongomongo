{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3806eaf-ef11-48ec-a85a-dcc3d563ce97",
   "metadata": {},
   "source": [
    "#### Author: WEE LING HUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732f9120-9007-4f03-8e96-4d0dbf34203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from classes.TextPreprocessor import TextPreprocessor\n",
    "from classes.SentimentModelTrainer import SentimentModelTrainer\n",
    "from classes.TextCleaner import TextCleaner\n",
    "from classes.Lemmatizer import Lemmatizer\n",
    "from classes.MalayStemmer import MalayStemmer\n",
    "from pyspark.sql.functions import col, sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4e9503-d818-400c-a549-6db0400b1ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/11 21:34:11 WARN Utils: Your hostname, LAPTOP-NU7VPFG6. resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/11 21:34:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/11 21:34:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 56154)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/student/de-prj/de-venv/lib/python3.10/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/student/de-prj/de-venv/lib/python3.10/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/home/student/de-prj/de-venv/lib/python3.10/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/student/de-prj/de-venv/lib/python3.10/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93108629-28ef-4de2-b87e-963fa5ae6c6d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cbdf38-65f6-4ec6-8932-3b3656581571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total rows : 300\n",
      "+--------+--------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+------------------------------+-------------+---------+\n",
      "|User ID |Name    |Followers Count|Tweet                                                                                                                                                                                   |Location              |Tweet Time                    |Friends Count|Sentiment|\n",
      "+--------+--------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+------------------------------+-------------+---------+\n",
      "|22594051|The Star|1903936        |Prime Minister Datuk Seri Anwar Ibrahim said the move comes as PTPTN's outstanding debt has nearly reached RM40bil to date.                                                             |Kuala Lumpur, Malaysia|Fri Apr 11 08:18:17 +0000 2025|274          |Positive |\n",
      "|22594051|The Star|1903936        |Sandakan Tourism Association president Teo Chee Kim said the east coast town is positioned to serve as a strategic international gateway.                                               |Kuala Lumpur, Malaysia|Fri Apr 11 08:16:51 +0000 2025|274          |Neutral  |\n",
      "|22594051|The Star|1903936        |The Malaysian pairing qualified for their first senior World Tour final after beating Puerto Rico's Angel Naranjo-Oscar Birriel in the semi-finals of the WTT Feeder Havirov tournament.|Kuala Lumpur, Malaysia|Fri Apr 11 08:10:11 +0000 2025|274          |Negative |\n",
      "|22594051|The Star|1903936        |The Penang Chief Minister said that all current projects reflected positive developments, thanks to strong collaboration between the parties involved.                                  |Kuala Lumpur, Malaysia|Fri Apr 11 08:10:11 +0000 2025|274          |Positive |\n",
      "|22594051|The Star|1903936        |Here are just some of the options available for music fans looking for a blast after dark.                                                                                              |Kuala Lumpur, Malaysia|Fri Apr 11 08:01:16 +0000 2025|274          |Neutral  |\n",
      "+--------+--------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+------------------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV correctly with header and infer schema\n",
    "\n",
    "# # Load data from HDFS\n",
    "# hdfs_path = \"hdfs://localhost:9000/user/hduser/raw_tweets\"\n",
    "# df = spark.read.json(hdfs_path) \n",
    "\n",
    "# # Show top 5 sample of the data\n",
    "# df.show(5)\n",
    "\n",
    "df = spark.read.csv(\n",
    "    \"file:///home/student/de-prj/tweets_output_with_sentiment.csv\",\n",
    "    header=True,  # Use first row as column names\n",
    "    inferSchema=True,  # Automatically detect data types\n",
    "    multiLine=True,  # Handle multi-line tweets\n",
    "    escape='\"'  # Fix misaligned text with quotes\n",
    ")\n",
    "\n",
    "# # Step 4: Rename columns if needed\n",
    "# correct_columns = [\"User ID\", \"Name\", \"Followers Count\", \"Tweet\", \"Location\", \"Tweet Time\", \"\" \"Sentiment\"]\n",
    "# df = df.toDF(*correct_columns)\n",
    "\n",
    "# Step 5: Show final cleaned DataFrame and row count\n",
    "print(f\" Total rows : {df.count()}\")\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d6017-27c5-41a6-9fe0-83c79e2f7145",
   "metadata": {},
   "source": [
    "## Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fa575e-8df2-4e03-86b0-74b720e4ef89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------------+-----+--------+----------+-------------+---------+\n",
      "|User ID|Name|Followers Count|Tweet|Location|Tweet Time|Friends Count|Sentiment|\n",
      "+-------+----+---------------+-----+--------+----------+-------------+---------+\n",
      "|      0|   0|              0|    1|       0|         0|            0|        0|\n",
      "+-------+----+---------------+-----+--------+----------+-------------+---------+\n",
      "\n",
      "Duplicate Rows: 0\n",
      "+---------+-------------------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+------------------------------+-------------+---------+\n",
      "|User ID  |Name               |Followers Count|Tweet                                                                                                                                                                                               |Location     |Tweet Time                    |Friends Count|Sentiment|\n",
      "+---------+-------------------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+------------------------------+-------------+---------+\n",
      "|61083422 |theSun             |181570         |Spain buys about 45 billion euros ($49.1 billion) of goods every year from China, its fourth-largest trading partner, but sells around 7.4 billion euros' worth.\\n#theSunMY #WorldNews #China #Spain|Petaling Jaya|Fri Apr 11 07:53:05 +0000 2025|401          |Positive |\n",
      "|61083422 |theSun             |181570         |He said they both agreed that ASEAN must engage in dialogue and negotiations with all relevant parties to achieve a peaceful and inclusive resolution for Myanmar                                   |Petaling Jaya|Thu Apr 10 12:07:28 +0000 2025|401          |Positive |\n",
      "|102098902|Free Malaysia Today|636734         |Cops nab man for allegedly attempting to rape jogger  #FMTNews #FMTEng                                                                                                                              |Malaysia     |Fri Apr 11 07:28:37 +0000 2025|2            |Negative |\n",
      "|55186601 |New Straits Times  |813984         |#NSTsports The world No. 6 are bracing for a tough challenge after easing through the first two rounds with straight-game victories over lower-ranked opponents                                     |Malaysia     |Fri Apr 11 07:31:18 +0000 2025|450          |Positive |\n",
      "|102098902|Free Malaysia Today|636734         |Taiwan charges Chinese ship captain with damaging undersea cables #FMTNews #FMTWorld                                                                                                                |Malaysia     |Fri Apr 11 04:43:31 +0000 2025|2            |Negative |\n",
      "+---------+-------------------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+------------------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total Records After Cleaning: 299\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# Remove rows with null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_count = df.count() - df.dropDuplicates().count()\n",
    "print(f\"Duplicate Rows: {duplicate_count}\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# Show first 5 rows after cleaning\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "# Print total number of records after cleaning\n",
    "print(f\"Total Records After Cleaning: {df.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f71a0e-db6e-43f3-b49f-66b1f77b6572",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e945e9-3bb9-4789-b92c-39199913afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------+-------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|Tweet                                                                                |clean_text                                                                        |words                                                                                             |filtered_words                                                                |lemmatized_words                                                         |stemmed_words                                                            |features                                                                                                                                                                                                                                          |label|\n",
      "+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------+-------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|'It's okay if we die, but don't cut down durian trees,' Raub farmer laments          |its okay if we die but dont cut down durian trees raub farmer laments             |[its, okay, if, we, die, but, dont, cut, down, durian, trees, raub, farmer, laments]              |[okay, die, dont, cut, durian, trees, raub, farmer, laments]                  |[okay, die, dont, cut, durian, tree, raub, farmer, lament]               |[okay, die, dont, cut, durian, tree, raub, farmer, lament]               |(10000,[955,1206,1318,3546,3810,4010,5871,7977,9427],[4.840242308167575,4.1470951276076295,4.43477720005941,4.840242308167575,4.840242308167575,4.840242308167575,4.840242308167575,3.92395157629342,3.92395157629342])                           |0.0  |\n",
      "|'PKR represents peopleâ€™s fight': Anwar tells members to pick right leaders           |pkr represents peoples fight anwar tells members to pick right leaders            |[pkr, represents, peoples, fight, anwar, tells, members, to, pick, right, leaders]                |[pkr, represents, peoples, fight, anwar, tells, members, pick, right, leaders]|[pkr, represent, people, fight, anwar, tell, member, pick, right, leader]|[pkr, represent, people, fight, anwar, tell, member, pick, right, leader]|(10000,[758,1526,1790,1850,2260,2526,4263,6790,7372,8717],[3.04848283893952,4.43477720005941,3.92395157629342,3.7416300194994654,4.840242308167575,3.92395157629342,3.453947947047684,4.43477720005941,4.840242308167575,4.43477720005941])       |0.0  |\n",
      "|Amid 'Abang Belon' speculation, MOH reminds only doctors can diagnose                |amid abang belon speculation moh reminds only doctors can diagnose                |[amid, abang, belon, speculation, moh, reminds, only, doctors, can, diagnose]                     |[amid, abang, belon, speculation, moh, reminds, doctors, diagnose]            |[amid, abang, belon, speculation, moh, reminds, doctor, diagnose]        |[amid, abang, belon, speculation, moh, reminds, doctor, diagnose]        |(10000,[777,4821,5048,5152,5263,5781,8274,8464],[4.1470951276076295,4.1470951276076295,4.840242308167575,4.840242308167575,4.840242308167575,4.840242308167575,3.92395157629342,4.840242308167575])                                               |1.0  |\n",
      "|Amid backlash, Kulai school says student expelled over doctored photos               |amid backlash kulai school says student expelled over doctored photos             |[amid, backlash, kulai, school, says, student, expelled, over, doctored, photos]                  |[amid, backlash, kulai, school, says, student, expelled, doctored, photos]    |[amid, backlash, kulai, school, say, student, expel, doctor, photo]      |[amid, backlash, kulai, school, say, student, expel, doctor, photo]      |(10000,[777,2679,3536,5367,5578,5862,8274,8377,8422],[4.1470951276076295,3.7416300194994654,3.336164911391301,4.43477720005941,3.92395157629342,1.8198174220232124,3.92395157629342,4.840242308167575,4.43477720005941])                          |0.0  |\n",
      "|Anwar receives honorary doctorate from US varsity, says not due to PM post           |anwar receives honorary doctorate from us varsity says not due to pm post         |[anwar, receives, honorary, doctorate, from, us, varsity, says, not, due, to, pm, post]           |[anwar, receives, honorary, doctorate, us, varsity, says, due, pm, post]      |[anwar, receives, honorary, doctorate, u, varsity, say, due, pm, post]   |[anwar, receives, honorary, doctorate, u, varsity, say, due, pm, post]   |(10000,[758,1049,3304,3783,5862,6174,7026,7973,8775,9717],[3.04848283893952,4.840242308167575,3.587479339672207,2.5889505095610796,1.8198174220232124,4.840242308167575,3.7416300194994654,4.840242308167575,4.840242308167575,4.840242308167575])|2.0  |\n",
      "|Azam failing at his job, NGO says after former asks for 'patience' over Sabah scandal|azam failing at his job ngo says after former asks for patience over sabah scandal|[azam, failing, at, his, job, ngo, says, after, former, asks, for, patience, over, sabah, scandal]|[azam, failing, job, ngo, says, former, asks, patience, sabah, scandal]       |[azam, fail, job, ngo, say, former, asks, patience, sabah, scandal]      |[azam, fail, job, ngo, say, former, asks, patience, sabah, scandal]      |(10000,[557,715,1797,3486,4160,4532,5862,6538,7363,9388],[4.43477720005941,4.43477720005941,3.92395157629342,4.840242308167575,4.840242308167575,4.840242308167575,1.8198174220232124,3.587479339672207,4.840242308167575,4.840242308167575])     |0.0  |\n",
      "|Bar seeks to appear in legal challenge against JAC Act                               |bar seeks to appear in legal challenge against jac act                            |[bar, seeks, to, appear, in, legal, challenge, against, jac, act]                                 |[bar, seeks, appear, legal, challenge, jac, act]                              |[bar, seek, appear, legal, challenge, jac, act]                          |[bar, seek, appear, legal, challenge, jac, act]                          |(10000,[171,5935,6928,7136,7332,8182,8471],[3.587479339672207,4.1470951276076295,4.1470951276076295,4.840242308167575,4.840242308167575,4.840242308167575,4.1470951276076295])                                                                    |2.0  |\n",
      "|Battle for Ayer Kuning seat begins tomorrow                                          |battle for ayer kuning seat begins tomorrow                                       |[battle, for, ayer, kuning, seat, begins, tomorrow]                                               |[battle, ayer, kuning, seat, begins, tomorrow]                                |[battle, ayer, kuning, seat, begin, tomorrow]                            |[battle, ayer, kuning, seat, begin, tomorrow]                            |(10000,[47,1513,6887,7202,7831,8025],[4.43477720005941,4.1470951276076295,4.840242308167575,3.92395157629342,3.92395157629342,4.43477720005941])                                                                                                  |0.0  |\n",
      "|Bidding for 'VIPS' number plate series opens tomorrow till April 15                  |bidding for vips number plate series opens tomorrow till april 15                 |[bidding, for, vips, number, plate, series, opens, tomorrow, till, april, 15]                     |[bidding, vips, number, plate, series, opens, tomorrow, till, april, 15]      |[bidding, vip, number, plate, series, open, tomorrow, till, april, 15]   |[bidding, vip, number, plate, series, open, tomorrow, till, april, 15]   |(10000,[2313,3174,4463,4925,5783,7760,7867,8025,8159,8519],[4.43477720005941,4.1470951276076295,4.840242308167575,4.840242308167575,3.336164911391301,4.840242308167575,2.760800766487739,4.43477720005941,4.1470951276076295,4.1470951276076295])|2.0  |\n",
      "|COMMENT | M'sia's strategic opportunity in US-China trade war                        |comment msias strategic opportunity in uschina trade war                          |[comment, msias, strategic, opportunity, in, uschina, trade, war]                                 |[comment, msias, strategic, opportunity, uschina, trade, war]                 |[comment, msias, strategic, opportunity, uschina, trade, war]            |[comment, msias, strategic, opportunity, uschina, trade, war]            |(10000,[419,6093,6477,6976,8516,8719,8902],[2.8943321591122615,4.840242308167575,4.840242308167575,3.92395157629342,4.1470951276076295,3.587479339672207,4.43477720005941])                                                                       |0.0  |\n",
      "+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------+-------------------------------------------------------------------------+-------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split dataset into training (80%) and testing (20%)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize the text preprocessing pipeline\n",
    "text_preprocessor = TextPreprocessor(input_col=\"Tweet\", label_col=\"Sentiment\")\n",
    "\n",
    "# Get the preprocessing pipeline\n",
    "pipeline = text_preprocessor.get_pipeline()\n",
    "\n",
    "# Fit and transform the training data\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "processed_train_data = pipeline_model.transform(train_data)\n",
    "\n",
    "# Transform the test data using the same pipeline model\n",
    "processed_test_data = pipeline_model.transform(test_data)\n",
    "\n",
    "# Show processed data\n",
    "processed_train_data.select(\"Tweet\", \"clean_text\", \"words\", \"filtered_words\", \"lemmatized_words\", \"stemmed_words\", \"features\", \"label\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab15049-af06-4e8a-a78f-bed14c3c1fa8",
   "metadata": {},
   "source": [
    "## Save Preprocessed Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303b5773-80a9-401e-bdf7-ed73bc825f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save processed training data\n",
    "processed_train_data.write.mode(\"overwrite\").parquet(\"hdfs://localhost:9000/user/student/processed_train_data\")\n",
    "\n",
    "# Save processed testing data\n",
    "processed_test_data.write.mode(\"overwrite\").parquet(\"hdfs://localhost:9000/user/student/processed_test_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b59bc80a-f858-40e8-ab81-1a2969bf3b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|label|sentiment|\n",
      "+-----+---------+\n",
      "|  2.0| Positive|\n",
      "|  1.0|  Neutral|\n",
      "|  0.0| Negative|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_train_data.select(\"label\", \"sentiment\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb45ab-f174-4dd5-9a40-0cfc9fe8f09e",
   "metadata": {},
   "source": [
    "## Save features and label for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848714e6-80e6-45fc-a21e-39c6625315da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to hdfs://localhost:9000/user/student/preprocessed_data.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Path to store processed data in HDFS\n",
    "hdfs_path = \"hdfs://localhost:9000/user/student/preprocessed_data.parquet\"\n",
    "\n",
    "# Save the DataFrame to HDFS in Parquet format\n",
    "processed_train_data.select(\"features\", \"label\").write.mode(\"overwrite\").parquet(hdfs_path)\n",
    "\n",
    "print(f\"Preprocessed data saved to {hdfs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659a45b-7f3d-449a-bdde-4962cb4fca0f",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89750de-0b35-4beb-bdcb-66e3e907691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from classes.TextPreprocessor import TextPreprocessor\n",
    "from classes.SentimentModelTrainer import SentimentModelTrainer\n",
    "from classes.TextCleaner import TextCleaner\n",
    "from classes.Lemmatizer import Lemmatizer\n",
    "from classes.MalayStemmer import MalayStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9feb3e52-489f-4d38-88cd-39f2ef2ed967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/11 23:54:25 WARN Utils: Your hostname, LAPTOP-NU7VPFG6. resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/11 23:54:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/11 23:54:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(10000,[955,1206,...|  0.0|\n",
      "|(10000,[758,1526,...|  0.0|\n",
      "|(10000,[777,4821,...|  1.0|\n",
      "|(10000,[777,2679,...|  0.0|\n",
      "|(10000,[758,1049,...|  2.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "\n",
    "# Load the preprocessed data from HDFS\n",
    "loaded_data = spark.read.parquet(\"hdfs://localhost:9000/user/student/preprocessed_data.parquet\")\n",
    "# Load training and testing data from HDFS\n",
    "train_data = spark.read.parquet(\"hdfs://localhost:9000/user/student/processed_train_data\")\n",
    "test_data = spark.read.parquet(\"hdfs://localhost:9000/user/student/processed_test_data\")\n",
    "\n",
    "\n",
    "# Verify the loaded data\n",
    "loaded_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62f14f-08a4-4e23-881c-322456e91ec2",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f63051-0c66-4d51-84d5-f99425ad5631",
   "metadata": {},
   "source": [
    "## 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c3d733-c1d5-4b0c-9928-c41919e8c0e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Set Performance: \n",
      "  Accuracy: 0.9921\n",
      "  Precision: 0.9921\n",
      "  Recall: 0.9921\n",
      "  F1: 0.9921\n",
      "\n",
      " Testing Set Performance: \n",
      "  Accuracy: 0.6596\n",
      "  Precision: 0.6577\n",
      "  Recall: 0.6596\n",
      "  F1: 0.6583\n",
      "\n",
      "!Possible Overfitting Detected! \n",
      "Training accuracy is 0.9921, but testing accuracy is 0.6596.\n",
      "Model successfully saved at hdfs://localhost:9000/user/student/nb_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trainer = SentimentModelTrainer()\n",
    "\n",
    "# Model: naive_bayes\n",
    "model_type = \"naive_bayes\"\n",
    "\n",
    "# Train the model\n",
    "trained_model = trainer.train(train_data, model_type)\n",
    "\n",
    "#Test the model\n",
    "evaluation_results = trainer.evaluate(trained_model, train_data, test_data)\n",
    "\n",
    "# Save the trained model to HDFS\n",
    "trained_model.write().overwrite().save(\"hdfs://localhost:9000/user/student/nb_model\")\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Model successfully saved at hdfs://localhost:9000/user/student/nb_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab87ee-f791-4c47-be49-460bff89a1d0",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af83a07a-e162-46ca-844d-a3f49e896edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Set Performance: \n",
      "  Accuracy: 0.5198\n",
      "  Precision: 0.7605\n",
      "  Recall: 0.5198\n",
      "  F1: 0.4788\n",
      "\n",
      " Testing Set Performance: \n",
      "  Accuracy: 0.4894\n",
      "  Precision: 0.6722\n",
      "  Recall: 0.4894\n",
      "  F1: 0.4176\n",
      "\n",
      " No significant overfitting detected. Model generalizes well! \n",
      "Model successfully saved at hdfs://localhost:9000/user/student/rf_model\n"
     ]
    }
   ],
   "source": [
    "trainer = SentimentModelTrainer()\n",
    "\n",
    "# Model name: random_forest\n",
    "model_type = \"random_forest\"  \n",
    "\n",
    "# Train the model\n",
    "trained_model = trainer.train(train_data, model_type)\n",
    "\n",
    "#Test the model\n",
    "evaluation_results = trainer.evaluate(trained_model, train_data, test_data)\n",
    "\n",
    "# Save the trained model to HDFS\n",
    "trained_model.write().overwrite().save(\"hdfs://localhost:9000/user/student/rf_model\")\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Model successfully saved at hdfs://localhost:9000/user/student/rf_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11b463-14b6-4d97-b415-73a914329bdf",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296fd3a1-d34f-4850-91bc-8c51b3b31409",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Set Performance: \n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1: 1.0000\n",
      "\n",
      " Testing Set Performance: \n",
      "  Accuracy: 0.5745\n",
      "  Precision: 0.5848\n",
      "  Recall: 0.5745\n",
      "  F1: 0.5720\n",
      "\n",
      "!Possible Overfitting Detected! \n",
      "Training accuracy is 1.0000, but testing accuracy is 0.5745.\n",
      "Model successfully saved at hdfs://localhost:9000/user/student/lr_model\n"
     ]
    }
   ],
   "source": [
    "trainer = SentimentModelTrainer()\n",
    "\n",
    "# Model name: logistic_regression\n",
    "model_type = \"logistic_regression\" \n",
    "\n",
    "# Train the model\n",
    "trained_model = trainer.train(train_data, model_type)\n",
    "\n",
    "#Test the model\n",
    "evaluation_results = trainer.evaluate(trained_model, train_data, test_data)\n",
    "\n",
    "# Save the trained model to HDFS\n",
    "trained_model.write().overwrite().save(\"hdfs://localhost:9000/user/student/lr_model\")\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Model successfully saved at hdfs://localhost:9000/user/student/lr_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac08f0-d6b7-44f4-aa27-bc6c8aa24073",
   "metadata": {},
   "source": [
    "## 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a84375e-8e17-4981-9811-fc7b770bc4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Set Performance: \n",
      "  Accuracy: 0.6190\n",
      "  Precision: 0.6805\n",
      "  Recall: 0.6190\n",
      "  F1: 0.6098\n",
      "\n",
      " Testing Set Performance: \n",
      "  Accuracy: 0.5532\n",
      "  Precision: 0.5800\n",
      "  Recall: 0.5532\n",
      "  F1: 0.5194\n",
      "\n",
      " No significant overfitting detected. Model generalizes well! \n",
      "Model successfully saved at hdfs://localhost:9000/user/student/dt_model\n"
     ]
    }
   ],
   "source": [
    "trainer = SentimentModelTrainer()\n",
    "\n",
    "# Model name: decision_tree\n",
    "model_type = \"decision_tree\"  \n",
    "\n",
    "# Train the model\n",
    "trained_model = trainer.train(train_data, model_type)\n",
    "\n",
    "#Test the model\n",
    "evaluation_results = trainer.evaluate(trained_model, train_data, test_data)\n",
    "\n",
    "# Save the trained model to HDFS\n",
    "trained_model.write().overwrite().save(\"hdfs://localhost:9000/user/student/dt_model\")\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"Model successfully saved at hdfs://localhost:9000/user/student/dt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f440b1-25b0-4bae-8490-e92c99d7e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
