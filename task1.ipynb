{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf35e53-7b5e-404c-b0b9-dd1476d364db",
   "metadata": {},
   "source": [
    "## Author: TAN ZHI WEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2196d98-fb96-47de-99c1-7f4cb7123ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Add this import statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe3357-736e-4753-8317-17411b9e4ddc",
   "metadata": {},
   "source": [
    "# get_tweet_userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a4dfcc-17be-4bcd-ab3c-4fe10d56548d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.get_tweet_userID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import the get_tweet_userID module\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_tweet_userID\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_user_input\u001b[39m():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the username: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data.get_tweet_userID'"
     ]
    }
   ],
   "source": [
    "# Import the get_tweet_userID module\n",
    "import data.get_tweet_userID\n",
    "\n",
    "def get_user_input():\n",
    "    return input(\"Enter the username: \")\n",
    "\n",
    "def main():\n",
    "    # Call the main function from get_tweet_userID module\n",
    "    data.get_tweet_userID.main()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70154e03-833f-4c53-a683-484f75fef1d8",
   "metadata": {},
   "source": [
    "# fetch_tweet_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9737d992-c3ad-4f2d-9e7b-71f31db928f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 22594051 The Star\n",
    "## 55186601 NST_Online\n",
    "## 18040230 malaysiakini\n",
    "## 61083422 theSundaily\n",
    "## 102098902 Free Malaysia Today \n",
    "## 145550026 Herald Malaysia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71b86cb-f234-4a0c-bcab-0e457f9c2a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 50 tweets for user 22594051\n",
      "Fetched 50 tweets for user 55186601\n",
      "Fetched 50 tweets for user 18040230\n",
      "Fetched 50 tweets for user 61083422\n",
      "Fetched 50 tweets for user 102098902\n",
      "Fetched 50 tweets for user 145550026\n",
      "\n",
      "Successfully fetched data for all users!\n",
      "Total tweets fetched: 300\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Author: Tan Zhi Wei\n",
    "#------------------------\n",
    "\n",
    "import requests  # For making HTTP requests\n",
    "import csv       # For writing data to CSV\n",
    "import re        # For regular expression to remove URLs\n",
    "\n",
    "url = \"https://twitter241.p.rapidapi.com/user-tweets\"\n",
    "user_ids = [\"22594051\", \"55186601\", \"18040230\", \"61083422\", \"102098902\", \"145550026\"]  # List of user IDs\n",
    "count_per_user = 50  \n",
    "headers = {\n",
    "    \"x-rapidapi-key\": \"6edb283a6cmshee06689689cfd50p13b4c8jsnf64bdb417da6\",\n",
    "    \"x-rapidapi-host\": \"twitter241.p.rapidapi.com\"\n",
    "}\n",
    "total_tweets_fetched = 0\n",
    "all_tweets_by_user = {}\n",
    "\n",
    "# Open a CSV file to write the output\n",
    "with open('tweets_output.csv', mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # Write the header\n",
    "    csvwriter.writerow(['User ID', 'Name', 'Followers Count', 'Tweet'])\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        # We'll potentially make multiple requests with pagination to get more tweets\n",
    "        cursor = None\n",
    "        tweets_for_this_user = 0\n",
    "        full_texts_for_user = []\n",
    "        \n",
    "        # Make multiple requests until we reach our desired count or run out of tweets\n",
    "        while tweets_for_this_user < count_per_user:\n",
    "            # Add cursor to querystring if we have one\n",
    "            if cursor:\n",
    "                querystring = {\"user\": user_id, \"count\": \"20\", \"cursor\": cursor}\n",
    "            else:\n",
    "                querystring = {\"user\": user_id, \"count\": \"20\"}\n",
    "                \n",
    "            response = requests.get(url, headers=headers, params=querystring)\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Parse the JSON response\n",
    "                data = response.json()\n",
    "                \n",
    "                # Initialize variables for this batch\n",
    "                batch_tweets = 0\n",
    "                next_cursor = None\n",
    "                \n",
    "                # Extract tweets and look for cursor for pagination\n",
    "                instructions = data.get(\"result\", {}).get(\"timeline\", {}).get(\"instructions\", [])\n",
    "                \n",
    "                for instruction in instructions:\n",
    "                    if instruction.get(\"type\") == \"TimelineAddEntries\":\n",
    "                        entries = instruction.get(\"entries\", [])\n",
    "                        for entry in entries:\n",
    "                            # Check if this is a cursor entry\n",
    "                            if entry.get(\"entryId\", \"\").startswith(\"cursor-bottom\"):\n",
    "                                content = entry.get(\"content\", {})\n",
    "                                if content.get(\"cursorType\") == \"Bottom\":\n",
    "                                    next_cursor = content.get(\"value\")\n",
    "                                continue\n",
    "                                \n",
    "                            tweet_result = entry.get(\"content\", {}).get(\"itemContent\", {}).get(\"tweet_results\", {}).get(\"result\", {})\n",
    "                            full_text = tweet_result.get(\"legacy\", {}).get(\"full_text\", \"\")\n",
    "                            user_name = tweet_result.get(\"core\", {}).get(\"user_results\", {}).get(\"result\", {}).get(\"legacy\", {}).get(\"name\", \"\")\n",
    "                            followers_count = tweet_result.get(\"core\", {}).get(\"user_results\", {}).get(\"result\", {}).get(\"legacy\", {}).get(\"followers_count\", 0)\n",
    "                            \n",
    "                            # Limit followers count to 10 digits\n",
    "                            if followers_count > 9999999999:\n",
    "                                followers_count = 9999999999\n",
    "                            \n",
    "                            if full_text:\n",
    "                                # Remove URLs from the full_text and strip whitespace\n",
    "                                full_text = re.sub(r'http\\S+', '', full_text).strip()\n",
    "                                # Append the full_text to the list\n",
    "                                full_texts_for_user.append(full_text)\n",
    "                                # Write to CSV\n",
    "                                csvwriter.writerow([user_id, user_name, followers_count, full_text])\n",
    "                                batch_tweets += 1\n",
    "                                # Break if we've reached our limit\n",
    "                                if len(full_texts_for_user) >= count_per_user:\n",
    "                                    break\n",
    "                \n",
    "                tweets_for_this_user += batch_tweets\n",
    "                \n",
    "                # If we didn't get any tweets in this batch or no next cursor, break\n",
    "                if batch_tweets == 0 or not next_cursor or len(full_texts_for_user) >= count_per_user:\n",
    "                    break\n",
    "                    \n",
    "                # Set the cursor for the next request\n",
    "                cursor = next_cursor\n",
    "                \n",
    "                # Add a small delay to avoid rate limiting (optional)\n",
    "                # import time\n",
    "                # time.sleep(1)\n",
    "            else:\n",
    "                print(f\"Error for user {user_id}: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                break\n",
    "        \n",
    "        # Store tweets for this user\n",
    "        all_tweets_by_user[user_id] = full_texts_for_user\n",
    "        total_tweets_fetched += len(full_texts_for_user)\n",
    "        \n",
    "        print(f\"Fetched {len(full_texts_for_user)} tweets for user {user_id}\")\n",
    "\n",
    "# Check if we have data for all users\n",
    "if len(all_tweets_by_user) == len(user_ids):\n",
    "    print(\"\\nSuccessfully fetched data for all users!\")\n",
    "else:\n",
    "    print(f\"\\nFetched data for {len(all_tweets_by_user)} out of {len(user_ids)} users\")\n",
    "print(f\"Total tweets fetched: {total_tweets_fetched}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e4364-d8ab-4b74-9be6-bb4d81173fdc",
   "metadata": {},
   "source": [
    "# label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300e08e8-6453-4eb2-af8c-58f666441b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution:\n",
      "Sentiment\n",
      "Negative    111\n",
      "Neutral     101\n",
      "Positive     88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of tweets with sentiment:\n",
      "    User ID      Name  Followers Count  \\\n",
      "0  22594051  The Star          1903879   \n",
      "1  22594051  The Star          1903879   \n",
      "2  22594051  The Star          1903879   \n",
      "3  22594051  The Star          1903879   \n",
      "4  22594051  The Star          1903879   \n",
      "\n",
      "                                               Tweet                Location  \\\n",
      "0   The Umno president said there was no such issue.  Kuala Lumpur, Malaysia   \n",
      "1  Perikatan Nasional's candidate for the Ayer Ku...  Kuala Lumpur, Malaysia   \n",
      "2  Police said 77 fatal accident cases were recor...  Kuala Lumpur, Malaysia   \n",
      "3  It was partially decomposed and may have spent...  Kuala Lumpur, Malaysia   \n",
      "4  \"Retaliatory US-China tariffs are damaging to ...  Kuala Lumpur, Malaysia   \n",
      "\n",
      "                       Tweet Time  Friends Count Sentiment  \n",
      "0  Sat Apr 12 05:33:16 +0000 2025            274  Negative  \n",
      "1  Sat Apr 12 05:32:02 +0000 2025            274   Neutral  \n",
      "2  Sat Apr 12 05:23:12 +0000 2025            274  Negative  \n",
      "3  Sat Apr 12 05:22:39 +0000 2025            274  Negative  \n",
      "4  Sat Apr 12 04:00:20 +0000 2025            274  Negative  \n",
      "\n",
      "Sentiment distribution by user:\n",
      "Sentiment  Negative  Neutral  Positive\n",
      "User ID                               \n",
      "18040230         21       18        11\n",
      "22594051         22       11        17\n",
      "55186601         19       17        14\n",
      "61083422         21       12        17\n",
      "102098902        13       28         9\n",
      "145550026        15       15        20\n",
      "\n",
      "Percentage of sentiment by user:\n",
      "Sentiment  Negative  Neutral  Positive\n",
      "User ID                               \n",
      "18040230       42.0     36.0      22.0\n",
      "22594051       44.0     22.0      34.0\n",
      "55186601       38.0     34.0      28.0\n",
      "61083422       42.0     24.0      34.0\n",
      "102098902      26.0     56.0      18.0\n",
      "145550026      30.0     30.0      40.0\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Author: Tan Zhi Wei\n",
    "#------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('tweets_output.csv')\n",
    "\n",
    "# Initialize the Vader SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to classify sentiment\n",
    "def classify_sentiment(tweet):\n",
    "    # Check if the tweet is a string\n",
    "    if pd.isna(tweet) or not isinstance(tweet, str):\n",
    "        return 'Unknown'  # Handle NaN or non-string values\n",
    "    \n",
    "    sentiment_score = analyzer.polarity_scores(tweet)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis on the 'Tweet' column\n",
    "df['Sentiment'] = df['Tweet'].apply(classify_sentiment)\n",
    "\n",
    "# Count the number of tweets with each sentiment\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "print(\"Sentiment distribution:\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Display the first few rows of the dataframe with sentiment\n",
    "print(\"\\nSample of tweets with sentiment:\")\n",
    "print(df.head())\n",
    "\n",
    "# Calculate sentiment distribution by user\n",
    "print(\"\\nSentiment distribution by user:\")\n",
    "sentiment_by_user = df.groupby(['User ID', 'Sentiment']).size().unstack(fill_value=0)\n",
    "print(sentiment_by_user)\n",
    "\n",
    "# Calculate the percentage of positive, negative, and neutral tweets for each user\n",
    "sentiment_percentage = sentiment_by_user.div(sentiment_by_user.sum(axis=1), axis=0) * 100\n",
    "print(\"\\nPercentage of sentiment by user:\")\n",
    "print(sentiment_percentage.round(2))\n",
    "\n",
    "# Save the result to a new CSV\n",
    "df.to_csv('tweets_output_with_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99926b45-14bb-42c5-9266-f8184caec280",
   "metadata": {},
   "source": [
    "# kafka_producer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e138611f-cefc-47b2-b2a7-085ec3fe1a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to PoliticsNewsTopic\n",
      "Sent tweet from The Star to SportsNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to BusinessNewsTopic\n",
      "Sent tweet from The Star to BusinessNewsTopic\n",
      "Sent tweet from The Star to BusinessNewsTopic\n",
      "Sent tweet from The Star to EntertainmentNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to PoliticsNewsTopic\n",
      "Sent tweet from The Star to BusinessNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to PoliticsNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to SportsNewsTopic\n",
      "Sent tweet from The Star to PoliticsNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to PoliticsNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to BusinessNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to EntertainmentNewsTopic\n",
      "Sent tweet from The Star to SportsNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to EntertainmentNewsTopic\n",
      "Sent tweet from The Star to PoliticsNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from The Star to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to EntertainmentNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to BusinessNewsTopic\n",
      "Sent tweet from New Straits Times to EntertainmentNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to PoliticsNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to SportsNewsTopic\n",
      "Sent tweet from New Straits Times to BusinessNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from New Straits Times to BusinessNewsTopic\n",
      "Sent tweet from New Straits Times to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to SportsNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to BusinessNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to PoliticsNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to SportsNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to PoliticsNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to BusinessNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to PoliticsNewsTopic\n",
      "Sent tweet from malaysiakini.com to PoliticsNewsTopic\n",
      "Sent tweet from malaysiakini.com to PoliticsNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to SportsNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from malaysiakini.com to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to BusinessNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to EntertainmentNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to SportsNewsTopic\n",
      "Sent tweet from theSun to EntertainmentNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to SportsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to BusinessNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to SportsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to BusinessNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to SportsNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to SportsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to SportsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from theSun to PoliticsNewsTopic\n",
      "Sent tweet from theSun to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to SportsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to SportsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to SportsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to BusinessNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to BusinessNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to SportsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to PoliticsNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to EntertainmentNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from Free Malaysia Today to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to PoliticsNewsTopic\n",
      "Sent tweet from heraldmalaysia to PoliticsNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to PoliticsNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to EntertainmentNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to PoliticsNewsTopic\n",
      "Sent tweet from heraldmalaysia to EntertainmentNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to SportsNewsTopic\n",
      "Sent tweet from heraldmalaysia to SportsNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to EntertainmentNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to MalaysiaNewsTopic\n",
      "Sent tweet from heraldmalaysia to PoliticsNewsTopic\n",
      "All tweets have been sent to Kafka\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Author: Tan Zhi Wei\n",
    "#------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "\n",
    "# Define CATEGORY_KEYWORDS dictionary\n",
    "CATEGORY_KEYWORDS = {\n",
    "    'PoliticsNewsTopic': [\n",
    "        'parliament', 'minister', 'government', 'election', 'policy', 'vote', \n",
    "        'cabinet', 'PM', 'democracy', 'corruption', 'political', 'politician',\n",
    "        'law', 'bill', 'constitution', 'amendment', 'opposition', 'campaign',\n",
    "        'UMNO', 'PAS', 'PKR', 'DAP', 'Bersatu', 'Pakatan', 'Barisan', 'budget'\n",
    "    ],\n",
    "    'BusinessNewsTopic': [\n",
    "        'economy', 'market', 'stock', 'investment', 'company', 'business', \n",
    "        'trade', 'finance', 'bank', 'ringgit', 'profit', 'revenue', 'CEO',\n",
    "        'entrepreneur', 'startup', 'commerce', 'industry', 'economic', \n",
    "        'inflation', 'recession', 'growth', 'GST', 'tax', 'BURSA', 'FDI'\n",
    "    ],\n",
    "    'SportsNewsTopic': [\n",
    "        'football', 'badminton', 'hockey', 'athlete', 'tournament', 'championship',\n",
    "        'league', 'match', 'player', 'coach', 'team', 'sport', 'medal', 'win',\n",
    "        'game', 'score', 'FIFA', 'Olympic', 'Petronas', 'stadium', 'final',\n",
    "        'competition', 'record', 'JDT', 'Selangor', 'Perak', 'Malaysia Super League'\n",
    "    ],\n",
    "    'EntertainmentNewsTopic': [\n",
    "        'movie', 'music', 'concert', 'celebrity', 'actor', 'actress', 'film',\n",
    "        'entertainment', 'drama', 'show', 'artist', 'singer', 'star', 'TV',\n",
    "        'Netflix', 'performance', 'premiere', 'award', 'festival', 'viral',\n",
    "        'album', 'song', 'talent', 'meme', 'trending', 'Astro', 'Media Prima'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load your CSV data\n",
    "df = pd.read_csv('tweets_output_with_sentiment.csv')\n",
    "\n",
    "# Initialize Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Define function to categorize tweets based on keywords\n",
    "def categorize_tweet(tweet_text):\n",
    "    # Ensure tweet_text is a string\n",
    "    if isinstance(tweet_text, str):  # Check if tweet_text is a string\n",
    "        tweet_text = tweet_text.lower()  # Make the text case-insensitive\n",
    "        for category, keywords in CATEGORY_KEYWORDS.items():\n",
    "            if any(keyword in tweet_text for keyword in keywords):  # Check if any keyword matches\n",
    "                return category\n",
    "    return 'MalaysiaNewsTopic'  # Default topic if no category is found or invalid tweet\n",
    "\n",
    "# Iterate and send data to the appropriate Kafka topic\n",
    "for index, row in df.iterrows():\n",
    "    tweet_data = {\n",
    "        'user_id': row['User ID'],\n",
    "        'name': row['Name'],\n",
    "        'followers_count': row['Followers Count'],\n",
    "        'tweet_text': row['Tweet'],\n",
    "        'sentiment': row['Sentiment']\n",
    "    }\n",
    "\n",
    "    # Categorize the tweet into the correct topic\n",
    "    topic = categorize_tweet(row['Tweet'])\n",
    "\n",
    "    # Send each row to the appropriate Kafka topic\n",
    "    producer.send(topic, value=tweet_data)\n",
    "\n",
    "    # Print confirmation (optional)\n",
    "    print(f\"Sent tweet from {row['Name']} to {topic}\")\n",
    "\n",
    "# Close the producer\n",
    "producer.flush()\n",
    "producer.close()\n",
    "print(\"All tweets have been sent to Kafka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be230fc9-91a0-4d1c-891a-c9826b985cf5",
   "metadata": {},
   "source": [
    "# kafka_consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b30e2f98-df13-4611-ad08-fee88b104ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Topics to verify:\n",
      "1. PoliticsNewsTopic\n",
      "2. BusinessNewsTopic\n",
      "3. SportsNewsTopic\n",
      "4. EntertainmentNewsTopic\n",
      "5. MalaysiaNewsTopic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number of the topic you want to verify:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking messages in BusinessNewsTopic...\n",
      "Message 1: {'user_id': 22594051, 'name': 'The Star', 'followers_count': 1903879, 'tweet_text': '\"Can we have the best of both worlds? Big, sporty, exciting, luxurious cars that are also economical to buy and run?\\n\\n\"Simply put, yes.\" - Ravindran Kurusamy', 'Location': 'Kuala Lumpur, Malaysia', 'Tweet Time': 'Sat Apr 12 03:40:15 +0000 2025', 'Friends Count': 274, 'sentiment': 'Positive'}\n",
      "Message 2: {'user_id': 22594051, 'name': 'The Star', 'followers_count': 1903879, 'tweet_text': 'These toys have managed to transcend the traditional toy market, appealing to the emotional and psychological needs of young adults.', 'Location': 'Kuala Lumpur, Malaysia', 'Tweet Time': 'Sat Apr 12 03:30:16 +0000 2025', 'Friends Count': 274, 'sentiment': 'Positive'}\n",
      "Message 3: {'user_id': 22594051, 'name': 'The Star', 'followers_count': 1903879, 'tweet_text': '\"It would be premature to think the dangers posed by the US bond market dysfunction this week have suddenly disappeared.\" - Jamie McGeever', 'Location': 'Kuala Lumpur, Malaysia', 'Tweet Time': 'Sat Apr 12 03:15:12 +0000 2025', 'Friends Count': 274, 'sentiment': 'Negative'}\n",
      "Message 4: {'user_id': 22594051, 'name': 'The Star', 'followers_count': 1903879, 'tweet_text': 'Fahmi expressed optimism that the visit would not only strengthen economic ties but also deepen cultural and people-to-people connections between the two nations.', 'Location': 'Kuala Lumpur, Malaysia', 'Tweet Time': 'Sat Apr 12 02:15:11 +0000 2025', 'Friends Count': 274, 'sentiment': 'Positive'}\n",
      "Message 5: {'user_id': 22594051, 'name': 'The Star', 'followers_count': 1903879, 'tweet_text': 'The shifting trade dynamics between the US and China may present new openings for Malaysian entrepreneurs.', 'Location': 'Kuala Lumpur, Malaysia', 'Tweet Time': 'Sat Apr 12 01:28:23 +0000 2025', 'Friends Count': 274, 'sentiment': 'Positive'}\n",
      "Showing first 5 messages. Topic contains more messages...\n",
      "\n",
      "✅ Topic verification successful! Found 5 messages in BusinessNewsTopic.\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Author: Tan Zhi Wei\n",
    "#------------------------\n",
    "\n",
    "import json\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "# Function to consume messages from the selected topic\n",
    "def consume_messages_from_topic(selected_topic):\n",
    "    # Initialize Kafka consumer for the selected topic\n",
    "    consumer = KafkaConsumer(\n",
    "        selected_topic,  # The topic to verify\n",
    "        bootstrap_servers=['localhost:9092'],\n",
    "        auto_offset_reset='earliest',  # Start from the beginning of the topic\n",
    "        group_id='verification_group',  # A unique consumer group for this verification\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        consumer_timeout_ms=10000  # Exit after 10 seconds of no new messages\n",
    "    )\n",
    "\n",
    "    print(f\"Checking messages in {selected_topic}...\")\n",
    "    message_count = 0\n",
    "\n",
    "    # Try to consume messages\n",
    "    for message in consumer:\n",
    "        message_count += 1\n",
    "        print(f\"Message {message_count}: {message.value}\")\n",
    "        \n",
    "        # Optional: limit the number of messages to display\n",
    "        if message_count >= 5:\n",
    "            print(f\"Showing first 5 messages. Topic contains more messages...\")\n",
    "            break\n",
    "\n",
    "    # Close the consumer\n",
    "    consumer.close()\n",
    "\n",
    "    # Check if messages were found\n",
    "    if message_count > 0:\n",
    "        print(f\"\\n✅ Topic verification successful! Found {message_count} messages in {selected_topic}.\")\n",
    "    else:\n",
    "        print(f\"\\n❌ No messages found in {selected_topic}. Please check your producer code or Kafka setup.\")\n",
    "\n",
    "# Allow user to choose the topic\n",
    "available_topics = [\n",
    "    'PoliticsNewsTopic',\n",
    "    'BusinessNewsTopic',\n",
    "    'SportsNewsTopic',\n",
    "    'EntertainmentNewsTopic',\n",
    "    'MalaysiaNewsTopic'\n",
    "]\n",
    "\n",
    "print(\"Available Topics to verify:\")\n",
    "for i, topic in enumerate(available_topics, 1):\n",
    "    print(f\"{i}. {topic}\")\n",
    "\n",
    "# Ask the user to select a topic\n",
    "try:\n",
    "    topic_choice = int(input(\"\\nEnter the number of the topic you want to verify: \"))\n",
    "    if 1 <= topic_choice <= len(available_topics):\n",
    "        selected_topic = available_topics[topic_choice - 1]\n",
    "        consume_messages_from_topic(selected_topic)\n",
    "    else:\n",
    "        print(\"\\n❌ Invalid selection. Please choose a valid topic number.\")\n",
    "except ValueError:\n",
    "    print(\"\\n❌ Invalid input. Please enter a number.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd09f21-7648-40e9-b3e2-e447949bdbea",
   "metadata": {},
   "source": [
    "# store_data_to_HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d65fc9e-eacb-4632-850d-98188a55bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping consumer...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping consumer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsumer closed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/consumer/group.py:491\u001b[0m, in \u001b[0;36mKafkaConsumer.close\u001b[0;34m(self, autocommit, timeout_ms)\u001b[0m\n\u001b[1;32m    489\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClosing the KafkaConsumer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocommit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/coordinator/consumer.py:456\u001b[0m, in \u001b[0;36mConsumerCoordinator.close\u001b[0;34m(self, autocommit, timeout_ms)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_auto_commit_offsets_sync(timeout_ms\u001b[38;5;241m=\u001b[39mtimeout_ms)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConsumerCoordinator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/coordinator/base.py:808\u001b[0m, in \u001b[0;36mBaseCoordinator.close\u001b[0;34m(self, timeout_ms)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Close the coordinator, leave the current group,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m    and reset local generation / member_id\"\"\"\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_close_heartbeat_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_leave_group(timeout_ms\u001b[38;5;241m=\u001b[39mtimeout_ms)\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/coordinator/base.py:796\u001b[0m, in \u001b[0;36mBaseCoordinator._close_heartbeat_thread\u001b[0;34m(self, timeout_ms)\u001b[0m\n\u001b[1;32m    794\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStopping heartbeat thread\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 796\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_heartbeat_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mReferenceError\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/de-prj/de-venv/lib/python3.10/site-packages/kafka/coordinator/base.py:993\u001b[0m, in \u001b[0;36mHeartbeatThread.close\u001b[0;34m(self, timeout_ms)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_ms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    992\u001b[0m         timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheartbeat_interval_ms\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m    995\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeartbeat thread did not fully terminate during close\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1100\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m-> 1100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Author: Tan Zhi Wei\n",
    "#------------------------\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import uuid\n",
    "from kafka import KafkaConsumer\n",
    "from hdfs import InsecureClient\n",
    "\n",
    "# Initialize Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    'MalaysiaNewsTopic',  # Topic name\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    group_id='tweet_consumer_group',\n",
    "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
    ")\n",
    "\n",
    "# Initialize HDFS client\n",
    "hdfs_client = InsecureClient('http://localhost:9870', user='hduser')\n",
    "\n",
    "# Specify the HDFS directory\n",
    "hdfs_directory = '/user/hduser/raw_tweets/'\n",
    "\n",
    "def write_to_hdfs(data):\n",
    "    try:\n",
    "        # Generate unique filename with timestamp and UUID\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        unique_id = str(uuid.uuid4())[:8]  # Use first 8 chars of UUID for brevity\n",
    "        file_name = f\"tweets_raw_{timestamp}_{unique_id}.json\"\n",
    "        \n",
    "        # Full path to HDFS\n",
    "        hdfs_path = f\"{hdfs_directory}/{file_name}\"\n",
    "        \n",
    "        # Convert the data to JSON\n",
    "        data_str = json.dumps(data, ensure_ascii=False)\n",
    "        \n",
    "        # Write the data to HDFS\n",
    "        with hdfs_client.write(hdfs_path, encoding='utf-8') as writer:\n",
    "            writer.write(data_str)\n",
    "            \n",
    "        print(f\"Successfully wrote to HDFS: {hdfs_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to HDFS: {e}\")\n",
    "        return False\n",
    "\n",
    "# Batch processing option\n",
    "def write_batch_to_hdfs(batch_data, batch_size=10):\n",
    "    if not batch_data:\n",
    "        return True\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unique_id = str(uuid.uuid4())[:8]\n",
    "    file_name = f\"tweets_batch_{timestamp}_{unique_id}_{batch_size}.json\"\n",
    "    hdfs_path = f\"{hdfs_directory}/{file_name}\"\n",
    "    \n",
    "    data_str = json.dumps(batch_data, ensure_ascii=False)\n",
    "    \n",
    "    with hdfs_client.write(hdfs_path, encoding='utf-8') as writer:\n",
    "        writer.write(data_str)\n",
    "    \n",
    "    print(f\"Successfully wrote batch of {len(batch_data)} tweets to HDFS\")\n",
    "    return True\n",
    "\n",
    "# Main processing loop\n",
    "try:\n",
    "    # For batch processing\n",
    "    batch = []\n",
    "    batch_size = 10\n",
    "    \n",
    "    for message in consumer:\n",
    "        tweet_data = message.value\n",
    "        \n",
    "        # Ensure tweet data contains the fields we need\n",
    "        tweet_data = {\n",
    "            'user_id': tweet_data['user_id'],\n",
    "            'name': tweet_data['name'],\n",
    "            'followers_count': tweet_data['followers_count'],\n",
    "            'tweet_text': tweet_data['tweet_text'],\n",
    "            'sentiment': tweet_data.get('sentiment', 'Unknown')  # Include sentiment if available\n",
    "        }\n",
    "        \n",
    "        print(f\"Received tweet data: {tweet_data}\")\n",
    "        \n",
    "        # Write individual tweet data to HDFS\n",
    "        write_to_hdfs(tweet_data)\n",
    "        \n",
    "        # Batch processing logic\n",
    "        batch.append(tweet_data)\n",
    "        if len(batch) >= batch_size:\n",
    "            write_batch_to_hdfs(batch, batch_size)\n",
    "            batch = []  # Reset batch after writing\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping consumer...\")\n",
    "finally:\n",
    "    consumer.close()\n",
    "    print(\"Consumer closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7f24b-5c02-44de-b9bb-860959c559c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont RUN !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3fc1c-a523-4d67-9045-eacccd3c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data exits or not\n",
    "# hadoop fs -ls /user/hduser/raw_tweets/  \n",
    "# hadoop fs -cat /user/hduser/raw_tweets//tweets_raw_20250314_171804_7933c577.json\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
